var documenterSearchIndex = {"docs":
[{"location":"internals/#Internals-and-Design","page":"Internals & Design","title":"Internals & Design","text":"","category":"section"},{"location":"internals/#File-Interface","page":"Internals & Design","title":"File Interface","text":"","category":"section"},{"location":"internals/","page":"Internals & Design","title":"Internals & Design","text":"The JLDFile object mimics the API of Base.Dict as much as it can. In particular, keys, length, haskey, isempty, get, get! should work as expected.","category":"page"},{"location":"internals/#JLD2.TYPE_AS_DATA","page":"Internals & Design","title":"JLD2.TYPE_AS_DATA","text":"TYPE_AS_DATA::ScopedValue{Bool}\n\nSignal to the jlconvert function that the type being read will be treated as either data or a type. This is needed to allow a custom typemap function to return an Upgrade object when the type is going to be used for reconstructing an instance. (as a type)\n\n\n\n\n\n","category":"constant"},{"location":"internals/#JLD2.CommittedDatatype","page":"Internals & Design","title":"JLD2.CommittedDatatype","text":"CommittedDatatype <: H5Datatype\n\nReference to a shared datatype message (stored elsewhere in a file). These are stored in the _types group and indexed.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.CustomSerialization","page":"Internals & Design","title":"JLD2.CustomSerialization","text":"CustomSerialization{T,S}\n\nOn-disk representation for data that is written as if it were of Julia type T, but is read as type S.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.Dataset","page":"Internals & Design","title":"JLD2.Dataset","text":"Dataset\n\nA mutable struct representing an HDF5/JLD2 dataset with explicit control over metadata.\n\nThe Dataset type allows low-level access to dataset metadata and provides fine-grained control over how data is stored, including compression, chunking, and layout options. This is useful for advanced use cases where you need more control than the standard jldsave/load interface provides.\n\nFields\n\nparent::Group: The containing group or file\nname::String: Dataset name within the parent group\noffset::RelOffset: File offset where dataset header is stored (UNDEFINED_ADDRESS if unwritten)\ndatatype: HDF5 datatype specification for the dataset\ndataspace: Dataspace describing the dataset dimensions\nlayout: Data layout specification (contiguous, compact, or chunked)\nattributes::OrderedDict{String, Any}: Dataset attributes as key-value pairs\nchunk: Chunking specification (for chunked layouts)\nfilters: Filter pipeline for compression/transformation\nheader_chunk_info: Internal metadata for header management\n\nUsage\n\nDatasets are typically created using create_dataset, written with write_dataset, and read with read_dataset or retrieved with get_dataset.\n\nExample\n\njldopen(\"data.jld2\", \"w\") do f\n    # Create a dataset with compression\n    dset = JLD2.create_dataset(f, \"compressed_data\")\n    dset.filters = Deflate()\n    JLD2.write_dataset(dset, rand(1000, 1000))\n\n    # Add attributes\n    JLD2.add_attribute(dset, \"description\", \"Random data with compression\")\nend\n\nSee also: create_dataset, write_dataset, read_dataset, get_dataset\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.GlobalHeap","page":"Internals & Design","title":"JLD2.GlobalHeap","text":"GlobalHeap\n\nRepresents an HDF5 global heap structure.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.Group","page":"Internals & Design","title":"JLD2.Group","text":"Group(file::JLDFile, name::String)\nGroup(file::Group, name::String)\n\nConstruct a Group in file with name name. Groups are JLD2s equivalent of folders and may be nested, so file itself may alread be a Group or a JLDFile file handle.\n\nExample usage\n\njldopen(\"example.jld2\", \"w\") do f\n    g = Group(f, \"subgroup\")\n    g[\"data\"] = 42\nend\n\njldopen(\"example.jld2\") do f\n    g = f[\"subgroup\"]\n    f[\"subgroup/data\"] == g[\"data\"]\nend\n\nKeyword arguments:\n\nest_num_entries::Int = 4\nest_link_name_len::Int = 8\n\nDetermine how much (additional) empty space should be allocated for the group description. (list of entries) This can be useful for performance when one expects to append many additional datasets after first writing the file.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.Group-Tuple{JLD2.JLDFile, AbstractString}","page":"Internals & Design","title":"JLD2.Group","text":"Group(f::JLDFile, name::AbstractString)\n\nConstruct an empty group named name at the top level of JLDFile f.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.Group-Union{Tuple{T}, Tuple{JLD2.Group{T}, AbstractString}} where T","page":"Internals & Design","title":"JLD2.Group","text":"Group(g::Group, name::AbstractString)\n\nConstruct a group named name as a child of group g.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.H5Datatype","page":"Internals & Design","title":"JLD2.H5Datatype","text":"abstract type H5Datatype\n\nSupertype of all HDF5 datatypes.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.HeaderMessage","page":"Internals & Design","title":"JLD2.HeaderMessage","text":"HeaderMessage\n\nHelper struct to read and write the first part of a header message.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.HeaderMessageIterator","page":"Internals & Design","title":"JLD2.HeaderMessageIterator","text":"mutable struct HeaderMessageIterator{IO}\nHeaderMessageIterator(f::JLDFile, offset::RelOffset)\n\nImplements an iterator over header messages.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.Hmessage","page":"Internals & Design","title":"JLD2.Hmessage","text":"Hmessage{IO}\n\nRepresentation of a Header Message in memory. Provides getproperty access to the fields of the message. Can also be used to construct and write custom messages.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.IndirectPointer","page":"Internals & Design","title":"JLD2.IndirectPointer","text":"IndirectPointer\n\nWhen writing data, we may need to enlarge the memory mapping, which would invalidate any memory addresses arising from the old mmap pointer. IndirectPointer holds an offset relative to the MemoryBackedIO. It defers computing a memory address until converted to a Ptr{T}, so the memory mapping can be enlarged and addresses will remain valid.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.InlineUnionEl","page":"Internals & Design","title":"JLD2.InlineUnionEl","text":"InlineUnionEl{T1,T2}(mask::UInt8, t1::T1, t2::T2)\n\nCustom serialization struct for two member isbits union fields e.g. in other structs or arrays. To indicate that t1 is relevant the mask takes the value UInt8(0) and for t2 the mask takes the value UInt8(255).\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.JLDFile","page":"Internals & Design","title":"JLD2.JLDFile","text":"JLDFile{T<:IO}\n\nJLD file object.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.JLDWriteSession","page":"Internals & Design","title":"JLD2.JLDWriteSession","text":"JLDWriteSession{T}\n\nA JLDWriteSession keeps track of references to serialized objects. If T is a Dict, h5offset maps an object ID (returned by calling objectid) to th RelOffset of the written dataset. If it is Union{}, then references are not tracked, and objects referenced multiple times are written multiple times.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.MemoryBackedIO","page":"Internals & Design","title":"JLD2.MemoryBackedIO","text":"MemoryBackedIO <: IO\n\nAbstract type for IO objects that are backed by memory in such a way that one can use pointer based unsafe_load and unsafe_store! operations after ensuring that there is enough memory allocated.\n\nIt needs to provide:\n\ngetproperty(io, :curptr) to get the current pointer\nensureroom(io, nb) to ensure that there are at least nb bytes available\nposition(io) to get the current (zero-based) position\nseek(io, pos) to set the current position (zero-based)\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.Message","page":"Internals & Design","title":"JLD2.Message","text":"Message{IO}\n\nRepresentation of a Message in memory. Provides getproperty access\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.ReadRepresentation","page":"Internals & Design","title":"JLD2.ReadRepresentation","text":"ReadRepresentation{T,ODR}\n\nA type encoding both the Julia type T and the on-disk (HDF5) representation ODR.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.RelOffset","page":"Internals & Design","title":"JLD2.RelOffset","text":"RelOffset\n\nRepresents an HDF5 relative offset. This differs from a file offset (used elsewhere) in that it is relative to the superblock base address. fileoffset and h5offset convert between RelOffsets and file offsets.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.SharedDatatype","page":"Internals & Design","title":"JLD2.SharedDatatype","text":"SharedDatatype <: H5Datatype\n\nReference to a shared datatype message (stored elsewhere in a file).\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.Upgrade","page":"Internals & Design","title":"JLD2.Upgrade","text":"Upgrade(T)\n\nSpecify an upgrade path for serialized structs using the typemap keyword argument and rconvert.\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.VirtualMapping","page":"Internals & Design","title":"JLD2.VirtualMapping","text":"VirtualMapping(source_file::String, source_dataset::String,\n               vds_selection=all_selection(), src_selection=all_selection())\n\nCreate a virtual dataset mapping that specifies how data from a source file should be mapped into the virtual dataset.\n\nArguments\n\nsource_file::String: Path to the source file (relative to virtual dataset file)\nsource_dataset::String: Name of the dataset within the source file\nvds_selection::HyperslabSelection: Selection in the virtual dataset space (default: entire dataset)\nsrc_selection::HyperslabSelection: Selection in the source dataset space (default: entire dataset)\n\nExamples\n\n# Map entire source dataset to virtual dataset\nmapping = VirtualMapping(\"./data.jld2\", \"measurements\")\n\n# Map specific regions (for advanced usage)\nvds_sel = HyperslabSelection([0], [1], [100], [1])  # First 100 elements\nsrc_sel = HyperslabSelection([0], [1], [100], [1])  # First 100 elements\nmapping = VirtualMapping(\"./subset.jld2\", \"data\", vds_sel, src_sel)\n\n\n\n\n\n","category":"type"},{"location":"internals/#JLD2.VirtualDataLayout-Tuple{Int64, UInt8}","page":"Internals & Design","title":"JLD2.VirtualDataLayout","text":"VirtualDataLayout(heap_address::Int64, heap_index::UInt8)\n\nCreate a DataLayout for virtual datasets that references mappings in the global heap.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.add_attribute","page":"Internals & Design","title":"JLD2.add_attribute","text":"add_attribute(dset::Dataset, name::String, data, wsession=JLDWriteSession())\n\nAdd an attribute with the specified name and data to a Dataset.\n\nAttributes are metadata key-value pairs associated with datasets. They can store additional information about the data such as units, descriptions, creation dates, or any other relevant metadata. Attributes can be added before or after the dataset has been written to the file.\n\nArguments\n\ndset::Dataset: The dataset to add the attribute to\nname::String: The attribute name (must be unique within the dataset)\ndata: The attribute value (can be any JLD2-serializable Julia object)\nwsession::JLDWriteSession: Optional write session for advanced usage (default: new session)\n\nThrows\n\nArgumentError: If an attribute with the same name already exists\n\nExamples\n\nBasic Attribute Usage\n\njldopen(\"data.jld2\", \"w\") do f\n    dset = JLD2.create_dataset(f, \"experiment_data\")\n\n    # Add various types of attributes\n    JLD2.add_attribute(dset, \"description\", \"Temperature measurements\")\n    JLD2.add_attribute(dset, \"units\", \"°C\")\n    JLD2.add_attribute(dset, \"measurement_date\", \"2024-01-15\")\n    JLD2.add_attribute(dset, \"sensor_id\", 42)\n    JLD2.add_attribute(dset, \"calibrated\", true)\n\n    # Write the actual data\n    JLD2.write_dataset(dset, temperature_readings)\nend\n\nComplex Attribute Data\n\njldopen(\"analysis.jld2\", \"w\") do f\n    dset = JLD2.create_dataset(f, \"results\")\n\n    # Attributes can store complex data\n    JLD2.add_attribute(dset, \"parameters\", Dict(\n        \"learning_rate\" => 0.01,\n        \"batch_size\" => 32,\n        \"epochs\" => 100\n    ))\n\n    JLD2.add_attribute(dset, \"processing_steps\", [\n        \"normalization\",\n        \"feature_extraction\",\n        \"model_training\"\n    ])\n\n    JLD2.write_dataset(dset, model_results)\nend\n\nReading Attributes\n\njldopen(\"data.jld2\", \"r\") do f\n    dset = JLD2.get_dataset(f, \"experiment_data\")\n\n    # Get all attributes\n    attrs = JLD2.attributes(dset)\n    for (attr_name, value) in attrs\n        println(attr_name, \": \", value)\n    end\n\n    # Access specific attributes\n    description = attrs[\"description\"]\n    units = attrs[\"units\"]\n    println(\"Data: \", description, \" (\", units, \")\")\nend\n\nAdding Attributes to Written Datasets\n\n# First session: create and write dataset\njldopen(\"data.jld2\", \"w\") do f\n    dset = JLD2.create_dataset(f, \"measurements\")\n    JLD2.write_dataset(dset, sensor_data)\nend\n\n# Second session: add attributes to existing dataset\njldopen(\"data.jld2\", \"a\") do f  # append mode\n    dset = JLD2.get_dataset(f, \"measurements\")\n    JLD2.add_attribute(dset, \"analysis_date\", string(today()))\n    JLD2.add_attribute(dset, \"processed_by\", \"analysis_v2.1\")\nend\n\nNotes\n\nAttribute names must be unique within each dataset\nAttributes can be added before or after writing the dataset data\nAttribute data can be any Julia object that JLD2 can serialize\nUse attributes to retrieve all attributes from a dataset\nExisting attributes cannot be modified; the dataset must be recreated to change them\n\nSee also: attributes, Dataset, create_dataset\n\n\n\n\n\n","category":"function"},{"location":"internals/#JLD2.attributes-Tuple{JLD2.Dataset}","page":"Internals & Design","title":"JLD2.attributes","text":"attributes(dset::Dataset; plain::Bool=false)\n\nReturn the attributes of a dataset as an OrderedDict. If plain is set to true then the values are returned as stored in the dataset object.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.behead-Tuple{UnionAll}","page":"Internals & Design","title":"JLD2.behead","text":"behead(T)\n\nGiven a UnionAll type, recursively eliminates the where clauses\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.bufferpos-Tuple{Union{JLD2.BufferedReader, JLD2.BufferedWriter}}","page":"Internals & Design","title":"JLD2.bufferpos","text":"bufferpos(io::Union{BufferedReader, BufferedWriter})\n\nGet the current position in the buffer.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.construct_array-Union{Tuple{T}, Tuple{IO, Type{T}, Int64}} where T","page":"Internals & Design","title":"JLD2.construct_array","text":"construct_array(io::IO, eltype, ndims::Int)\n\nConstruct array by reading ndims dimensions from io. Assumes io has already been seeked to the correct position.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.constructrr","page":"Internals & Design","title":"JLD2.constructrr","text":"constructrr(f::JLDFile, T::DataType, dt::CompoundType, attrs::Vector{ReadAttribute},\n            hard_failure::Bool=false)\n\nConstructs a ReadRepresentation for a given type. This is the generic method for all types not specially handled below.\n\nIf hard_failure is true, then throw a TypeMappingException instead of attempting reconstruction. This helps in cases where we can't know if reconstructed parametric types will have a matching memory layout without first inspecting the memory layout.\n\n\n\n\n\n","category":"function"},{"location":"internals/#JLD2.create_dataset-Tuple{JLD2.JLDFile, Vararg{Any}}","page":"Internals & Design","title":"JLD2.create_dataset","text":"create_dataset(parent, path, datatype=nothing, dataspace=nothing; layout=nothing, chunk=nothing, filters=FilterPipeline())\n\nCreate a new Dataset object with specified metadata, ready for writing data.\n\nThis function creates a dataset specification but does not write any data to the file. The dataset must be written using write_dataset to actually store data. This two-step process allows you to configure compression, attributes, and other metadata before writing.\n\nArguments\n\nparent::Union{JLDFile, Group}: The containing file or group for the new dataset\npath::Union{String, Nothing}: Path to the dataset relative to parent. If nothing, creates an unnamed dataset\ndatatype: HDF5 datatype specification. If nothing, will be inferred from data during writing\ndataspace: Dataspace describing dimensions. If nothing, will be inferred from data during writing\n\nKeyword Arguments\n\nlayout: Data layout specification (LcContiguous, LcCompact, or LcChunked)\nchunk: Chunking specification for chunked layouts\nfilters::FilterPipeline: Compression/transformation pipeline (default: no compression)\n\nReturns\n\nDataset: A mutable dataset object ready for configuration and writing\n\nExamples\n\nBasic Usage\n\njldopen(\"data.jld2\", \"w\") do f\n    dset = JLD2.create_dataset(f, \"my_data\")\n    JLD2.write_dataset(dset, [1, 2, 3, 4, 5])\nend\n\nWith Compression\n\njldopen(\"data.jld2\", \"w\") do f\n    dset = JLD2.create_dataset(f, \"compressed_array\")\n    dset.filters = Deflate()  # Add gzip compression\n    JLD2.write_dataset(dset, rand(10000))\nend\n\nWith Attributes\n\njldopen(\"data.jld2\", \"w\") do f\n    dset = JLD2.create_dataset(f, \"experiment_results\")\n    JLD2.add_attribute(dset, \"experiment_id\", \"exp_001\")\n    JLD2.add_attribute(dset, \"date\", \"2024-01-15\")\n    JLD2.add_attribute(dset, \"temperature\", 23.5)\n    JLD2.write_dataset(dset, measurement_data)\nend\n\nUnnamed Dataset\n\njldopen(\"data.jld2\", \"w\") do f\n    dset = JLD2.create_dataset(f, nothing)  # unnamed\n    JLD2.write_dataset(dset, temporary_data)\nend\n\nNotes\n\nThe dataset is not written to the file until write_dataset is called\nDatatype and dataspace are usually inferred automatically from the data\nCompression filters can be added after creation but before writing\nAttributes can be added before or after writing (see add_attribute)\n\nSee also: write_dataset, Dataset, add_attribute, Deflate\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.create_virtual_dataset-Tuple{Union{JLD2.Group, JLD2.JLDFile}, String, Tuple, Type, Vector{JLD2.VirtualMapping}}","page":"Internals & Design","title":"JLD2.create_virtual_dataset","text":"create_virtual_dataset(parent, name, dims, element_type, mappings::Vector{VirtualMapping})\n\nCreate a virtual dataset that combines data from multiple source files according to the specified mappings.\n\nArguments\n\nparent::Union{JLDFile, Group}: The containing file or group\nname::String: Name of the virtual dataset\ndims::Tuple: Dimensions of the virtual dataset\nelement_type::Type: Element type of the virtual dataset (e.g., Float64, Int32)\nmappings::Vector{VirtualMapping}: List of source file mappings\n\nReturns\n\nRelOffset: Offset where the virtual dataset was written\n\nExamples\n\n# Simple virtual dataset combining multiple files\njldopen(\"virtual.jld2\", \"w\") do f\n    # Create source files first\n    jldsave(\"data1.jld2\"; x = fill(1.0, 3))\n    jldsave(\"data2.jld2\"; x = fill(2.0, 3))\n\n    # Create virtual dataset mappings\n    mappings = [\n        VirtualMapping(\"./data1.jld2\", \"x\"),\n        VirtualMapping(\"./data2.jld2\", \"x\")\n    ]\n\n    # Create virtual dataset that combines them horizontally\n    create_virtual_dataset(f, \"combined\", (3, 2), Float64, mappings)\nend\n\n# Read back the virtual dataset\njldopen(\"virtual.jld2\", \"r\") do f\n    data = f[\"combined\"]  # Returns [1.0 2.0; 1.0 2.0; 1.0 2.0]\nend\n\nPattern-based mappings\n\nFor sequential files, you can use pattern-based mappings:\n\nmappings = [VirtualMapping(\"./sub-%b.jld2\", \"x\")]  # Expands to sub-0.jld2, sub-1.jld2, etc.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.create_virtual_dataset-Tuple{Union{JLD2.Group, JLD2.JLDFile}, String, Vector{String}, String}","page":"Internals & Design","title":"JLD2.create_virtual_dataset","text":"create_virtual_dataset(parent, name, source_files::Vector{String}, dataset_name::String)\n\nCreate a virtual dataset by automatically inferring dimensions and type from the first source file.\n\nThis is a convenience function that automatically determines the virtual dataset dimensions and element type by inspecting the first source file. All source files are expected to contain datasets with the same name and compatible dimensions.\n\nArguments\n\nparent::Union{JLDFile, Group}: The containing file or group\nname::String: Name of the virtual dataset to create\nsource_files::Vector{String}: List of source file paths (relative to virtual dataset file)\ndataset_name::String: Name of the dataset within each source file\n\nReturns\n\nRelOffset: Offset where the virtual dataset was written\n\nExamples\n\n# Simple automatic inference\njldopen(\"virtual.jld2\", \"w\") do f\n    # Source files already exist with compatible datasets\n    source_files = [\"./data1.jld2\", \"./data2.jld2\", \"./data3.jld2\"]\n\n    # Automatically infer dimensions and type from first file\n    JLD2.create_virtual_dataset(f, \"combined\", source_files, \"measurements\")\nend\n\nThis function will:\n\nOpen the first source file and inspect the specified dataset\nDetermine the element type and individual dataset dimensions\nCalculate the combined virtual dataset dimensions (horizontally concatenated)\nCreate the virtual dataset with appropriate mappings\n\nNotes\n\nAll source files must contain a dataset with the specified name\nAll datasets should have compatible dimensions for proper concatenation\nThe virtual dataset will combine data horizontally (column-wise)\nElement types must be compatible across all source files\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.default_typemap-Tuple{JLD2.JLDFile, String, Vector}","page":"Internals & Design","title":"JLD2.default_typemap","text":"default_typemap(f::JLDFile, typepath::String, params)\n\nDefault type mapping function used by JLD2 to resolve data types read from files.\n\nArguments:\n\nf::JLDFile: The JLD file being read.\ntypepath::String: The path to the type as a string, e.g. \"Main.MyModule.MyType\".\nparams: A list of type parameters for the type (may be empty).\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.fileoffset-Tuple{JLD2.JLDFile, JLD2.RelOffset}","page":"Internals & Design","title":"JLD2.fileoffset","text":"fileoffset(f::JLDFile, x::RelOffset)\n\nConverts an offset x relative to the superblock of file f to an absolute offset.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.find_type-Tuple{String}","page":"Internals & Design","title":"JLD2.find_type","text":"find_type(typepath::String)\n\nFinds a type in the loaded modules by its path as a string. The type path should be a dot-separated string, e.g. \"Main.MyModule.MyType\". If the type is found, it returns the corresponding DataType or UnionAll. If the type is not found, it returns nothing.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.flag2uint-Tuple{UInt8}","page":"Internals & Design","title":"JLD2.flag2uint","text":"flag2uint(flag::UInt8)\n\nI Map the lowest to bits of flag to a UInt type, mapping 0 to UInt8, 1 to UInt16, 2 to UInt32, and 3 to UInt64.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.get_dataset-Tuple{JLD2.JLDFile, Vararg{Any}}","page":"Internals & Design","title":"JLD2.get_dataset","text":"get_dataset(parent::Union{JLDFile, Group}, name::String)\n\nRetrieve a Dataset object from a file without reading the actual data.\n\nThis function loads the dataset metadata (datatype, dataspace, attributes, etc.) but does not read the actual data values. This is useful for inspecting dataset properties, accessing attributes, or preparing for selective data reading. The returned Dataset object can be used with read_dataset, readmmap, or array indexing operations.\n\nArguments\n\nparent::Union{JLDFile, Group}: The file or group containing the dataset\nname::String: Name or path of the dataset relative to the parent\n\nReturns\n\nDataset: A dataset object containing metadata and providing access to the data\n\nThrows\n\nKeyError: If no dataset with the specified name exists\n\nExamples\n\nBasic Usage\n\njldopen(\"data.jld2\", \"r\") do f\n    dset = JLD2.get_dataset(f, \"my_array\")\n\n    # Inspect the dataset without reading data\n    println(\"Dataset: \", dset.name)\n    println(\"Datatype: \", typeof(dset.datatype))\n\n    # Read the actual data\n    data = JLD2.read_dataset(dset)\nend\n\nInspecting Dataset Metadata\n\njldopen(\"experiment.jld2\", \"r\") do f\n    dset = JLD2.get_dataset(f, \"results\")\n\n    # Display comprehensive dataset information\n    display(dset)  # Shows datatype, dataspace, layout, attributes, etc.\n\n    # Access specific metadata\n    attrs = JLD2.attributes(dset)\n    println(\"Attributes: \", attrs)\n\n    # Check if dataset supports memory mapping\n    if JLD2.ismmappable(dset)\n        println(\"Dataset can be memory-mapped\")\n        mmap_data = JLD2.readmmap(dset)\n    else\n        println(\"Dataset requires full loading\")\n        data = JLD2.read_dataset(dset)\n    end\nend\n\nWorking with Nested Groups\n\njldopen(\"structured_data.jld2\", \"r\") do f\n    # Access dataset in nested group\n    dset = JLD2.get_dataset(f, \"experiments/trial_001/results\")\n\n    # Or navigate step by step\n    exp_group = f[\"experiments\"]\n    trial_group = exp_group[\"trial_001\"]\n    dset = JLD2.get_dataset(trial_group, \"results\")\nend\n\nArray Access Patterns\n\njldopen(\"large_array.jld2\", \"r\") do f\n    dset = JLD2.get_dataset(f, \"big_matrix\")\n\n    # Different ways to access the data\n    full_data = dset[]                    # Read all data\n    single_value = dset[1, 1]            # Read single element\n    row = dset[1, :]                     # Read first row\n    submatrix = dset[1:10, 1:10]        # Read submatrix\n\n    # Equivalent to read_dataset for full data\n    same_data = JLD2.read_dataset(dset)\n    @assert full_data == same_data\nend\n\nInspecting File Contents\n\nfunction explore_datasets(filename)\n    jldopen(filename, \"r\") do f\n        for dataset_name in keys(f)\n            try\n                dset = JLD2.get_dataset(f, dataset_name)\n                println(\"Dataset: \", dataset_name)\n                println(\"  Type: \", typeof(dset.datatype))\n\n                attrs = JLD2.attributes(dset)\n                if !isempty(attrs)\n                    println(\"  Attributes: \", keys(attrs))\n                end\n                println()\n            catch e\n                println(dataset_name, \": Not a dataset or error: \", e)\n            end\n        end\n    end\nend\n\nNotes\n\nThis function only loads metadata, not the actual data values\nUse read_dataset or array indexing to access the data\nThe Dataset object provides detailed information when displayed\nSupports both absolute and relative paths within the file hierarchy\nMemory-mapped access may be available for suitable datasets (see ismmappable)\n\nSee also: read_dataset, Dataset, attributes, readmmap, ismmappable\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.h5offset-Tuple{JLD2.JLDFile, Integer}","page":"Internals & Design","title":"JLD2.h5offset","text":"h5offset(f::JLDFile, x::Integer)\n\nConverts an absolute file offset x to an offset relative to the superblock of file f.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.ismmappable-Tuple{JLD2.Dataset}","page":"Internals & Design","title":"JLD2.ismmappable","text":"ismmappable(dset::Dataset)\n\nCheck if a dataset can be memory-mapped. This can be useful for large arrays and for editing written arrays.\n\nAn Array dataset may be mmapped if:     - JLD2.samelayout(T) == true: The element type is isbits and has a size that either 1, 2, 4, or a multiple of 8 bytes.     - Uncompressed: Compressed arrays cannot be memory-mapped     - Uses a contiguous layout: This is true for all array datasets written by JLD2 with version ≥ v0.4.52     - Windows: The file must be opened in read-only mode. This is a limitation of Mmap on Windows.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.isset-Tuple{Any, Any}","page":"Internals & Design","title":"JLD2.isset","text":"isset(flag, bit)\n\nReturn true if the bit-th bit of flag is set. (starting from 0)   \n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.jld_finalizer-Tuple{JLD2.JLDFile{JLD2.MmapIO}}","page":"Internals & Design","title":"JLD2.jld_finalizer","text":"jld_finalizer(f::JLDFile)\n\nWhen a JLDFile is finalized, it is possible that the MmapIO has been munmapped, since Julia does not guarantee finalizer order. This means that the underlying file may be closed before we get a chance to write to it.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.jldopen","page":"Internals & Design","title":"JLD2.jldopen","text":"jldopen(file, mode::AbstractString; iotype=MmapIO, compress=false, typemap=JLD2.default_typemap)\n\nOpens a JLD2 file at path file. Alternatively file may be a suitable IO object.\n\nOptions for mode:\n\n\"r\": Open for reading only, failing if no file exists\n\"r+\": Open for reading and writing, failing if no file exists\n\"w\"/\"w+\": Open for reading and writing, overwriting the file if it already exists\n\"a\"/\"a+\": Open for reading and writing, creating a new file if none exists, but               preserving the existing file if one is present\n\n\n\n\n\n","category":"function"},{"location":"internals/#JLD2.jldsave","page":"Internals & Design","title":"JLD2.jldsave","text":"jldsave(filename; kwargs...)\njldsave(filename, compress; kwargs...)\njldsave(filename, compress, iotype; kwargs...)\n\nCreates a JLD2 file at filename and stores the variables given as keyword arguments.\n\nExamples\n\njldsave(\"example.jld2\"; a=1, b=2, c)\n\nis equivalent to\n\njldopen(\"example.jld2\", \"w\") do f\n    f[\"a\"] = 1\n    f[\"b\"] = 2\n    f[\"c\"] = c\nend\n\nTo choose the io type IOStream instead of the default MmapIO use  jldsave(fn, IOStream; kwargs...).\n\n\n\n\n\n","category":"function"},{"location":"internals/#JLD2.jlwrite-Tuple{IO, Tuple}","page":"Internals & Design","title":"JLD2.jlwrite","text":"jlwrite(io::IO, x::Tuple)\n\nAttempt to write a tuple to io by writing each element of the tuple in order.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.links_size-Tuple{Any}","page":"Internals & Design","title":"JLD2.links_size","text":"links_size(pairs)\n\nReturns the size of several link messages. pairs is an iterator of String => RelOffset pairs.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.load_attributes","page":"Internals & Design","title":"JLD2.load_attributes","text":"load_attributes(f::JLDFile, name::AbstractString)\nload_attributes(g::Group, name::AbstractString)\nload_attributes(g::Group)\nload_attributes(f::JLDFile, offset::RelOffset)\n\nReturn a list of attributes attached to the dataset or group.\n\n\n\n\n\n","category":"function"},{"location":"internals/#JLD2.load_data_or_dict-Tuple{Union{JLD2.Group, JLD2.JLDFile}, AbstractString}","page":"Internals & Design","title":"JLD2.load_data_or_dict","text":"load_data_or_dict(g::Union{JLDFile,Group}, varname::AbstractString)\n\nReturn the value of key varname but if it represents a Group load the group as a nested dictionary.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.load_datatypes-Tuple{JLD2.JLDFile}","page":"Internals & Design","title":"JLD2.load_datatypes","text":"load_datatypes(f::JLDFile)\n\nPopulate f.datatypes and f.jlh5types with all of the committed datatypes from a file. We need to do this before writing to make sure we reuse written datatypes.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.load_object-Tuple{Any}","page":"Internals & Design","title":"JLD2.load_object","text":"load_object(filename)\n\nReturns the only available object from the JLD2 file filename (The stored object name is inconsequential). If the file contains more than one or no objects, the function throws an ArgumentError.\n\nFor loading more than one object, use @load macro, jldopen or the FileIO API.\n\nExample\n\nTo load the only object from the JLD2 file example.jld2:\n\nhello = \"world\"\nsave_object(\"example.jld2\", hello)\nhello_loaded = load_object(\"example.jld2\")\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.loadnesteddict-Tuple{Union{JLD2.Group, JLD2.JLDFile}}","page":"Internals & Design","title":"JLD2.loadnesteddict","text":"loadnesteddict(g::Union{JLDFile, Group})\n\nReturn a dictionary with all data contained in group or file. Nested groups are loaded as nested dictionaries.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.lookup_offset-Tuple{JLD2.Group, AbstractString}","page":"Internals & Design","title":"JLD2.lookup_offset","text":"lookup_offset(g::Group, name::AbstractString) -> RelOffset\n\nLookup the offset of a dataset in a group. Returns UNDEFINED_ADDRESS if the dataset is not present. Does not inspect unwritten_child_groups.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.pathize-Tuple{JLD2.Group, AbstractString, Bool}","page":"Internals & Design","title":"JLD2.pathize","text":"pathize(g::Group, name::AbstractString, create::Bool) -> Tuple{Group,String}\n\nConverts a path to a group and name object. If create is true, any intermediate groups will be created, and the dataset name will be checked for uniqueness with existing names.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.prewrite-Tuple{JLD2.JLDFile}","page":"Internals & Design","title":"JLD2.prewrite","text":"prewrite(f::JLDFile)\n\nCheck that a JLD file is actually writable, and throw an error if not. Sets the written flag on the file.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.print_header_messages-Tuple{JLD2.JLDFile, AbstractString}","page":"Internals & Design","title":"JLD2.print_header_messages","text":"print_header_messages(f::JLDFile, name::AbstractString)\nprint_header_messages(g::Group, name::AbstractString)\nprint_header_messages(f::JLDFile, offset::RelOffset)\n\nPrints the header messages of a group or dataset in a file.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.printtoc-Tuple{JLD2.JLDFile}","page":"Internals & Design","title":"JLD2.printtoc","text":"printtoc([io::IO,] f::JLDFile [; numlines])\n\nPrints an overview of the contents of f to the IO.\n\nUse the optional numlines parameter to restrict the amount of items listed.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.read_array!","page":"Internals & Design","title":"JLD2.read_array!","text":"read_array!(v::Array, f::JLDFile, rr)\n\nFill the array v with the contents of JLDFile f at the current position, assuming a ReadRepresentation rr.\n\n\n\n\n\n","category":"function"},{"location":"internals/#JLD2.read_attr_data-Tuple{JLD2.JLDFile, JLD2.ReadAttribute, JLD2.H5Datatype, JLD2.ReadRepresentation}","page":"Internals & Design","title":"JLD2.read_attr_data","text":"read_attr_data(f::JLDFile, attr::ReadAttribute, expected_datatype::H5Datatype,\n               rr::ReadRepresentation)\n\njlread data from an attribute, assuming a specific HDF5 datatype and ReadRepresentation. If the HDF5 datatype does not match, throws an UnsupportedFeatureException. This allows better type stability while simultaneously validating the data.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.read_attr_data-Tuple{JLD2.JLDFile, JLD2.ReadAttribute}","page":"Internals & Design","title":"JLD2.read_attr_data","text":"read_attr_data(f::JLDFile, attr::ReadAttribute)\n\njlread data from an attribute.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.read_compressed_array!","page":"Internals & Design","title":"JLD2.read_compressed_array!","text":"read_compressed_array!(v::Array, f::JLDFile, rr, data_length::Int, Val(filter_id))\n\nFill the array v with the compressed contents of JLDFile f at the current position, assuming a ReadRepresentation rr and that the compressed data has length data_length.\n\n\n\n\n\n","category":"function"},{"location":"internals/#JLD2.read_data","page":"Internals & Design","title":"JLD2.read_data","text":"read_data(f::JLDFile, dataspace::ReadDataspace, datatype_class::UInt8,\n          datatype_offset::Int64, data_offset::Int64[, filters::FilterPipeline,\n          header_offset::RelOffset, attributes::Vector{ReadAttribute}])\n\nRead data from a file. If datatype_class is typemax(UInt8), the datatype is assumed to be committed, and datatype_offset points to the offset of the committed datatype's header. Otherwise, datatype_offset points to the offset of the datatype attribute.\n\n\n\n\n\n","category":"function"},{"location":"internals/#JLD2.read_dataset-Tuple{JLD2.Dataset}","page":"Internals & Design","title":"JLD2.read_dataset","text":"read_dataset(dset::Dataset)\n\nRead and return the data stored in a Dataset.\n\nThis function reads the complete dataset from the file and reconstructs the original Julia object. The dataset must have been previously written to the file using write_dataset. For large arrays, consider using readmmap for memory-mapped access if supported.\n\nArguments\n\ndset::Dataset: The dataset object, typically obtained from get_dataset\n\nReturns\n\nThe reconstructed Julia object that was originally stored in the dataset\n\nExamples\n\nBasic Reading\n\njldopen(\"data.jld2\", \"r\") do f\n    dset = JLD2.get_dataset(f, \"my_data\")\n    data = JLD2.read_dataset(dset)\n    println(\"Read data: \", data)\nend\n\nReading with Type Information\n\njldopen(\"data.jld2\", \"r\") do f\n    dset = JLD2.get_dataset(f, \"matrix_data\")\n\n    # Inspect the dataset before reading\n    println(\"Dataset info:\")\n    display(dset)  # Shows detailed dataset metadata\n\n    # Read the actual data\n    matrix = JLD2.read_dataset(dset)\n    println(\"Matrix size: \", size(matrix))\nend\n\nReading Multiple Datasets\n\njldopen(\"experiment.jld2\", \"r\") do f\n    # Read experiment results\n    results_dset = JLD2.get_dataset(f, \"results\")\n    results = JLD2.read_dataset(results_dset)\n\n    # Read parameters\n    params_dset = JLD2.get_dataset(f, \"parameters\")\n    params = JLD2.read_dataset(params_dset)\n\n    println(\"Results: \", results)\n    println(\"Parameters: \", params)\nend\n\nAlternative: Direct Array Access\n\njldopen(\"data.jld2\", \"r\") do f\n    dset = JLD2.get_dataset(f, \"large_array\")\n\n    # For arrays, you can also use indexing\n    first_element = dset[1]           # Read single element\n    subarray = dset[1:10, 1:5]      # Read subarray\n    full_array = dset[]              # Read entire array (same as read_dataset)\nend\n\nNotes\n\nThe dataset must have been written to the file before it can be read\nAll data is loaded into memory; for large arrays consider readmmap\nCompressed datasets are automatically decompressed during reading\nCustom Julia types are automatically reconstructed if the type definitions are available\n\nSee also: get_dataset, readmmap, Dataset, write_dataset\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.read_scalar","page":"Internals & Design","title":"JLD2.read_scalar","text":"read_scalar(f::JLDFile, rr, header_offset::RelOffset)\n\nRead raw data representing a scalar with read representation rr from the current position of JLDFile f. header_offset is the RelOffset of the object header, used to resolve cycles.\n\n\n\n\n\n","category":"function"},{"location":"internals/#JLD2.read_size-Tuple{IO, UInt8}","page":"Internals & Design","title":"JLD2.read_size","text":"read_size(io::IO, flags::UInt8)\n\nLoads a variable-length size according to flags\n\nExpects that the first two bits of flags mean:\n\n0:   The size of the Length of Link Name field is 1 byte.\n1:   The size of the Length of Link Name field is 2 bytes.\n2:   The size of the Length of Link Name field is 4 bytes.\n3:   The size of the Length of Link Name field is 8 bytes.\n\nReturns the size as an Int.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.readas-Tuple{Any}","page":"Internals & Design","title":"JLD2.readas","text":"readas(::Type)::Type\n\nExperimental feature:  JLD2.readas can be overloaded to override which type a saved type is read as, and is used together with custom serialization using JLD2.writeas.\n\nThe typical case is custom serialization of parametric types, where not all type parameters are available during reading.  Consider the following example for an anonymous function fun inside a Foo\n\nstruct Foo{F<:Function}\n    fun::F\nend\nstruct FooSerialization\n    fun\nend\nJLD2.writeas(::Type{<:Foo}) = FooSerialization\nBase.convert(::Type{<:FooSerialization}, f::Foo) = FooSerialization(f.fun)\n\nJLD2.readas(::Type{<:FooSerialization}) = Foo\nstruct UndefinedFunction <:Function\n    fun\nend\n(f::UndefinedFunction)(args...; kwargs...) = error(\"The function $(f.fun) is not defined\")\nfunction Base.convert(::Type{<:Foo}, f::FooSerialization)\n    isa(f.fun, Function) && return Foo(f.fun)\n    return Foo(UndefinedFunction(f.fun))\nend\n\nIf we include these definitions, call jldsave(\"foo.jld2\"; foo=Foo(x->x^2)), restart julia, include the definitions again, and call foo = jldopen(\"foo.jld2\") do io; io[\"foo\"]; end, we get foo::Foo{UndefinedFunction} and foo::FooSerialization with and without defining the JLD2.readas above, respectively.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.readmmap-Tuple{JLD2.Dataset}","page":"Internals & Design","title":"JLD2.readmmap","text":"readmmap(dset::Dataset)\n\nMemory-map a dataset. This can be useful for large arrays and for editing written arrays. See ismmappable for requirements.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.save_group-Tuple{JLD2.Group}","page":"Internals & Design","title":"JLD2.save_group","text":"save_group(g::Group) -> RelOffset\n\nStores a group to a file, updating it if it has already been saved. Returns UNDEFINED_ADDRESS if the group was already stored, or the offset of the new group otherwise.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.save_object-Tuple{Any, Any}","page":"Internals & Design","title":"JLD2.save_object","text":"save_object(filename, x)\n\nStores an object x in a new JLD2 file at filename. If a file exists at this path, it will be overwritten.\n\nSince the JLD2 format requires that all objects have a name, the object will be stored as single_stored_object. If you want to store more than one object, use @save macro, jldopen or the FileIO API.\n\nExample\n\nTo save the string hello to the JLD2 file example.jld2:\n\nhello = \"world\"\nsave_object(\"example.jld2\", hello)\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.shorttypestring-Tuple{Any}","page":"Internals & Design","title":"JLD2.shorttypestring","text":"shorttypestring(::Type{ <:UnknownType})\n\nConvert an UnknownType to a corresponding string. This is only used to create names for reconstructed types.\n\nSee also typestring.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.size_flag-Tuple{Integer}","page":"Internals & Design","title":"JLD2.size_flag","text":"size_flag(sz::Integer)::UInt8\n\nReturn the flag that represents the smallest integer type that can represent sz. 0 -> UInt8, 1 -> UInt16, 2 -> UInt32, 3 -> UInt64\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.size_size-Tuple{Integer}","page":"Internals & Design","title":"JLD2.size_size","text":"size_size(sz::Integer)\n\nReturn the number of bytes required to represent sz as an unsigned integer that actually exists. (e.g. UInt8, UInt16, UInt32, UInt64)\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.size_size2-Tuple{Integer}","page":"Internals & Design","title":"JLD2.size_size2","text":"size_size2(sz::Integer)\n\nReturn the number of bytes required to represent sz as an unsigned integer. Note: this does not check if the integer is a valid julia integer.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.skip_to_aligned!","page":"Internals & Design","title":"JLD2.skip_to_aligned!","text":"skip_to_aligned!(io, rel=0)\n\nSkip to nearest position aligned to a multiple of 8 bytes relative to rel.\n\n\n\n\n\n","category":"function"},{"location":"internals/#JLD2.symbol_length-Tuple{Symbol}","page":"Internals & Design","title":"JLD2.symbol_length","text":"symbol_length(x::Symbol)\n\nReturns the length of the string represented by x.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.typestring-Tuple{Any}","page":"Internals & Design","title":"JLD2.typestring","text":"typestring(::Type{ <:UnknownType})\n\nConvert an UnknownType to a corresponding string. This is only used for warning during reconstruction errors.\n\nSee also shorttypestring.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.uintofsize-Tuple{Any}","page":"Internals & Design","title":"JLD2.uintofsize","text":"uintofsize(sz::Integer)\n\nReturn the UInt type that has sz bytes.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.write_dataset","page":"Internals & Design","title":"JLD2.write_dataset","text":"write_dataset(dataset::Dataset, data, wsession::JLDWriteSession=JLDWriteSession())\n\nWrite data to file using the metadata and configuration stored in the Dataset object.\n\nThis function performs the actual data writing operation after a dataset has been created with create_dataset. The dataset must not have been written before (each dataset can only be written once). The data type and dataspace will be automatically inferred from the provided data if they weren't specified during dataset creation.\n\nArguments\n\ndataset::Dataset: The dataset object created with create_dataset\ndata: The data to write. Can be any Julia object that JLD2 can serialize\nwsession::JLDWriteSession: Optional write session for advanced usage (default: new session)\n\nReturns\n\nRelOffset: The file offset where the dataset was written\n\nThrows\n\nArgumentError: If the dataset has already been written to file\n\nExamples\n\nBasic Usage\n\njldopen(\"output.jld2\", \"w\") do f\n    dset = JLD2.create_dataset(f, \"my_array\")\n    JLD2.write_dataset(dset, [1, 2, 3, 4, 5])\nend\n\nWith Compression\n\njldopen(\"output.jld2\", \"w\") do f\n    dset = JLD2.create_dataset(f, \"large_data\")\n    dset.filters = Deflate()  # Add gzip compression\n\n    large_array = rand(Float64, 10000, 10000)\n    JLD2.write_dataset(dset, large_array)\n\n    println(\"Compressed data written successfully\")\nend\n\nWith Attributes and Multiple Datasets\n\njldopen(\"experiment.jld2\", \"w\") do f\n    # Dataset 1: Results with metadata\n    results_dset = JLD2.create_dataset(f, \"results\")\n    JLD2.add_attribute(results_dset, \"experiment\", \"trial_001\")\n    JLD2.add_attribute(results_dset, \"date\", \"2024-01-15\")\n    JLD2.write_dataset(results_dset, experimental_results)\n\n    # Dataset 2: Parameters\n    params_dset = JLD2.create_dataset(f, \"parameters\")\n    JLD2.write_dataset(params_dset, Dict(\"learning_rate\" => 0.01, \"epochs\" => 100))\nend\n\nNotes\n\nEach dataset can only be written once. Attempting to write again will throw an error\nData type and dataspace are automatically inferred if not provided during creation\nCompression filters must be set before writing\nAttributes can be added before or after writing\nThe write operation is atomic - either the entire dataset is written or an error is thrown\n\nSee also: create_dataset, Dataset, read_dataset, add_attribute\n\n\n\n\n\n","category":"function"},{"location":"internals/#JLD2.write_dataset_with_virtual_layout-Tuple{JLD2.JLDFile, Any, Any, JLD2.DataLayout, String}","page":"Internals & Design","title":"JLD2.write_dataset_with_virtual_layout","text":"write_dataset_with_virtual_layout(f::JLDFile, dataspace, datatype, layout::DataLayout, name::String)\n\nWrite a dataset header with virtual layout to the file.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.write_size-Tuple{IO, Integer}","page":"Internals & Design","title":"JLD2.write_size","text":"write_size(io::IO, sz::Integer)\n\nWrite the mininum number of bytes required to represent sz as (valid) unsigned integer.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.write_virtual_dataset-Tuple{JLD2.JLDFile, Any, Any, Vector{JLD2.VirtualMapping}, String}","page":"Internals & Design","title":"JLD2.write_virtual_dataset","text":"write_virtual_dataset(f::JLDFile, dataspace, datatype, mappings::Vector{VirtualMapping}, name::String)\n\nWrite a virtual dataset with the specified mappings to the HDF5/JLD2 file. This creates a proper HDF5 Virtual Dataset (VDS) format that can be read by both HDF5.jl and JLD2.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.write_virtual_mappings_to_heap-Tuple{JLD2.JLDFile, Vector{JLD2.VirtualMapping}}","page":"Internals & Design","title":"JLD2.write_virtual_mappings_to_heap","text":"write_virtual_mappings_to_heap(f::JLDFile, mappings::Vector{VirtualMapping})\n\nWrite virtual dataset mappings to the global heap and return the heap address and index.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.write_zerobytes-Tuple{Any, Any}","page":"Internals & Design","title":"JLD2.write_zerobytes","text":"write_zerobytes(io, n)\n\nWrite n zero bytes to io.\n\n\n\n\n\n","category":"method"},{"location":"internals/#JLD2.@load-Tuple{Any, Vararg{Any}}","page":"Internals & Design","title":"JLD2.@load","text":"@load filename var1 [var2 ...]\n\nLoad one or more variables var1,... from JLD2 file filename into the current scope and return a vector of the loaded variable names.\n\nFor interactive use, the form @load \"somefile.jld2\" will load all variables from \"somefile.jld2\" into the current scope. This form only supports literal file names and should be avoided in more permanent code so that it's clear where the variables come from.\n\nExample\n\nTo load the variables hello and foo from the file example.jld2, use\n\n@load \"example.jld2\" hello foo\n\n\n\n\n\n","category":"macro"},{"location":"internals/#JLD2.@pseudostruct-Tuple{Any, Any}","page":"Internals & Design","title":"JLD2.@pseudostruct","text":"@pseudostruct name begin ... end\n\nThe @pseudostruct macro is used to define constructor, size computation, show, and and optimized getproperty function for Messages. The allowed syntax elements are:\n\n@skip(n): Mark n bytes as empty.\n\n\n\n\n\n","category":"macro"},{"location":"internals/#JLD2.@save-Tuple{Any, Vararg{Any}}","page":"Internals & Design","title":"JLD2.@save","text":"@save filename var1 [var2 ...]\n@save filename {compress=true} var1 name2=var2\n\nWrite one or more variables var1,... from the current scope to a JLD2 file filename.\n\nFor interactive use you can save all variables in the current module's global scope using @save filename. More permanent code should prefer the explicit form to avoid saving unwanted variables.\n\nExample\n\nTo save the string hello and array xs to the JLD2 file example.jld2:\n\nhello = \"world\"\nxs = [1,2,3]\n@save \"example.jld2\" hello xs\n\nFor passing options to the saving command use {}\n\n@save \"example.jld2\" {compress=true} hello xs\n\nFor saving variables under a different name use regular assignment syntax\n\n@save \"example.jld2\" greeting=hello xarray = xs\n\n\n\n\n\n","category":"macro"},{"location":"troubleshooting/#Gotchas-and-Troubleshooting","page":"Troubleshooting","title":"Gotchas & Troubleshooting","text":"","category":"section"},{"location":"troubleshooting/#Objects-are-cached-during-loading","page":"Troubleshooting","title":"Objects are cached during loading","text":"","category":"section"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"JLD2 caches objects during loading. It may give you the same object twice. This can lead to surprising results if you edit loaded arrays. Note, the underlying file is not being edited!","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"using JLD2 #hide\njldsave(\"demo.jld2\", a=zeros(2))\nf = jldopen(\"demo.jld2\")\na = f[\"a\"] # bind loaded array to name `a`\na[1] = 42; # editing the underlying array\nf[\"a\"]\na = nothing # remove all references to the loaded array\nGC.gc(true) # call GC to remove the cache\nf[\"a\"] # a new copy is loaded from the file\nclose(f) #hide","category":"page"},{"location":"troubleshooting/#Cross-compatibility","page":"Troubleshooting","title":"Cross-compatibility","text":"","category":"section"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"JLD2 tries to write files in a way that allows you to load them on different operating systems and in particular both on 32bit and 64bit systems. However, many julia structs may be inherently different on different architectures making this task impossible. In particular, moving data from a 64bit system to a 32bit system is only guaranteed to work for basic datatypes.","category":"page"},{"location":"troubleshooting/#Security","page":"Troubleshooting","title":"Security","text":"","category":"section"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"Beware of opening JLD2 files from untrusted sources. A malicious file may execute code on your computer. See e.g. this project's issue #117. To check a file, you can use debug tooling provided by JLD2 to view what kinds of objects are stored. Details on the available tools are described below.","category":"page"},{"location":"troubleshooting/#Viewing-header-messages","page":"Troubleshooting","title":"Viewing header messages","text":"","category":"section"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"Following the HDF5 format specification, JLD2 stores metadata and all information required to interpret the stored data for each dataset in the form of so-called header messages. Each hdf5 group, dataset, and committed datatype consist of and object header followed by a variable number of header messages.","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"There exist different types of these to encode for the data type or the layout i.e. single element or array.","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"These can be printed for inspection using JLD2:","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"using JLD2 #hide\njldsave(\"test.jld2\";\n    a = 42,\n    b = [1,2,3,4,5],\n    c = (1,2),\n)\nf = jldopen(\"test.jld2\")\nJLD2.print_header_messages(f, \"a\")","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"Here we see, among other things, a","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"dataspace message which states that \"a\" is a single (scalar) element\ndatatype message\ndatalayout message of the compact type which means that the data is so small it was","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"directly stored as part of the message.","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"JLD2.print_header_messages(f, \"b\")","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"Important differences to \"a\" are that the dataspace now reports the dimensions of the array as (5,) and the the data layout has changed to contiguous which means that it is stored as a single block starting at the offset reported in data_address.","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"JLD2.print_header_messages(f, \"c\")","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"For dataset c we see that the datatype is a shared datatype which is stored elsewhere in the file and is referenced by its offset. This is, of course, also a regular hdf5 object and we can print its header messages by supplying the offset:","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"JLD2.print_header_messages(f, JLD2.RelOffset(4520))\nclose(f) #hide","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"This object consists of just two messages:","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"The datatype message defines the hdf5 datatype and therefore describes the byte layout","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"and field types.","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"The attribute message has the name julia_type and as payload the julia DataType","category":"page"},{"location":"troubleshooting/","page":"Troubleshooting","title":"Troubleshooting","text":"signature Tuple{Int64, Int64} which is needed for reconstruction.","category":"page"},{"location":"legacy/#Legacy","page":"Legacy","title":"Legacy","text":"","category":"section"},{"location":"legacy/","page":"Legacy","title":"Legacy","text":"This page lists features of JLD2 that are kept for legacy purposes. In particular, the following sections describes the @load and @save macros. They have been the default for many users but they unnecessarily introduce new macro-based syntax. Over time a range of issues have been opened by new users struggling with them. Since their inception, the Julia language has improved significantly and macros may no longer be necessary in this case.","category":"page"},{"location":"legacy/#@save-and-@load-macros","page":"Legacy","title":"@save and @load macros","text":"","category":"section"},{"location":"legacy/","page":"Legacy","title":"Legacy","text":"The @save and @load macros are the simplest way to interact with a JLD2 file. The @save macro writes one or more variables from the current scope to the JLD2 file. For example:","category":"page"},{"location":"legacy/","page":"Legacy","title":"Legacy","text":"using JLD2\nhello = \"world\"\nfoo = :bar\n@save \"example.jld2\" hello foo","category":"page"},{"location":"legacy/","page":"Legacy","title":"Legacy","text":"This writes the variables hello and foo to datasets in a new JLD2 file named example.jld2. The @load macro loads variables out of a JLD2 file:","category":"page"},{"location":"legacy/","page":"Legacy","title":"Legacy","text":"@load \"example.jld2\" hello foo","category":"page"},{"location":"legacy/","page":"Legacy","title":"Legacy","text":"This assigns the contents of the hello and foo datasets to variables of the same name in the current scope.","category":"page"},{"location":"legacy/","page":"Legacy","title":"Legacy","text":"It is best practice to explicitly name the variables to be loaded and saved from a file, so that it is clear from whence these variables arise. However, for convenience, JLD2 also provides variants of @load and @save that do not require variables to be named explicitly. When called with no variable arguments, @save <filename> writes all variables in the global scope of the current module to file <filename>, while @load <filename> loads all variables in file <filename>. When called with no variable arguments, @load requires that the file name is provided as a string literal, i.e., it is not possible to select the file at runtime.","category":"page"},{"location":"legacy/","page":"Legacy","title":"Legacy","text":"Additional customization is possible using assignment syntax and option passing:","category":"page"},{"location":"legacy/","page":"Legacy","title":"Legacy","text":"@save \"example.jld2\" bye=hello bar=foo\n@save \"example.jld2\" {compress=true} hello bar=foo","category":"page"},{"location":"legacy/#JLD2.@save","page":"Legacy","title":"JLD2.@save","text":"@save filename var1 [var2 ...]\n@save filename {compress=true} var1 name2=var2\n\nWrite one or more variables var1,... from the current scope to a JLD2 file filename.\n\nFor interactive use you can save all variables in the current module's global scope using @save filename. More permanent code should prefer the explicit form to avoid saving unwanted variables.\n\nExample\n\nTo save the string hello and array xs to the JLD2 file example.jld2:\n\nhello = \"world\"\nxs = [1,2,3]\n@save \"example.jld2\" hello xs\n\nFor passing options to the saving command use {}\n\n@save \"example.jld2\" {compress=true} hello xs\n\nFor saving variables under a different name use regular assignment syntax\n\n@save \"example.jld2\" greeting=hello xarray = xs\n\n\n\n\n\n","category":"macro"},{"location":"legacy/#JLD2.@load","page":"Legacy","title":"JLD2.@load","text":"@load filename var1 [var2 ...]\n\nLoad one or more variables var1,... from JLD2 file filename into the current scope and return a vector of the loaded variable names.\n\nFor interactive use, the form @load \"somefile.jld2\" will load all variables from \"somefile.jld2\" into the current scope. This form only supports literal file names and should be avoided in more permanent code so that it's clear where the variables come from.\n\nExample\n\nTo load the variables hello and foo from the file example.jld2, use\n\n@load \"example.jld2\" hello foo\n\n\n\n\n\n","category":"macro"},{"location":"advanced/#Advanced-Usage","page":"Advanced Usage","title":"Advanced Usage","text":"","category":"section"},{"location":"advanced/#Loading-plain-types","page":"Advanced Usage","title":"Loading plain types","text":"","category":"section"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"using JLD2 #hide\njldsave(\"test.jld2\"; z= 1.0 + im * 2.0)\nload(\"test.jld2\", \"z\")\nload(\"test.jld2\", \"z\"; plain=true)\n@__MODULE__","category":"page"},{"location":"advanced/#Explicit-Type-Remapping","page":"Advanced Usage","title":"Explicit Type Remapping","text":"","category":"section"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"Sometimes you store data using structs that you defined yourself or are shipped with some package and weeks later, when you want to load the data, the structs have changed.","category":"page"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"using JLD2 #hide\nstruct A\n    x::Int\nend\njldsave(\"example.jld2\"; a = A(42))","category":"page"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"This results in warnings and sometimes even errors when trying to load the file as demonstrated here.","category":"page"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"using JLD2 #hide\nstruct A{T}\n    x::T\nend\nload(\"example.jld2\")","category":"page"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"The JLDFile struct contains a typemap field that allows for explicit type remapping. You can define a struct that matches the old definition and load your data.","category":"page"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"using JLD2 #hide\nstruct A_old\n    x::Int\nend\nf = jldopen(\"example.jld2\",\"r\"; typemap=Dict(\"Main.A\" => A_old))\nf[\"a\"]","category":"page"},{"location":"advanced/#Upgrading-old-structures-on-load","page":"Advanced Usage","title":"Upgrading old structures on load","text":"","category":"section"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"The section above explains how you can make JLD2 load old structs with a different Datatype name as target. A different method for loading old data is described here:","category":"page"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"using JLD2 #hide\n# This is the old version of the struct stored in the file\nstruct OldStructVersion\n    x::Int\n    y::Float64\nend\norig = OldStructVersion(1,2.0)\njldsave(\"test.jld2\"; data=orig)","category":"page"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"using JLD2 #hide\n### new session\n\n# This is the new version of your struct\nstruct UpdatedStruct\n    x::Float64 # no longer int\n    y::Float64\n    z::Float64 # = x*y\nend\n\n# When upgrading a struct, JLD2 will load the fields of the old struct into a `NamedTuple`\n# and call `rconvert` on it. Here we implement a conversion method that returns an `UpdatedStruct`\nJLD2.rconvert(::Type{UpdatedStruct}, nt::NamedTuple) = UpdatedStruct(Float64(nt.x), nt.y, nt.x*nt.y)\n\n# Here we provide the `typemap` keyword argument. It is a dictionary mapping the stored struct name\n# to an `Upgrade` instance with the new struct.\nload(\"test.jld2\", \"data\"; typemap=Dict(\"Main.OldStructVersion\" => JLD2.Upgrade(UpdatedStruct)))","category":"page"},{"location":"advanced/#Full-control-over-type-reconstruction","page":"Advanced Usage","title":"Full control over type reconstruction","text":"","category":"section"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"The recommended and more powerful option is to take full control over type mapping by providing a custom mapping function that gets full access to all stored information including the type parameters. Example like above:","category":"page"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"struct OldStruct{T}\n    x::T\nend\n\nold_int = OldStruct(42)\nold_float = OldStruct(3.14)\njldsave(\"test.jld2\"; old_int, old_float, inttype=OldStruct{Int}, floattype=OldStruct{Float64}, )\n\nstruct NormalStruct{T}\n    x::T\nend\n\nstruct SquaredStruct{T}\n    xsquared::T\nend\n\nJLD2.rconvert(::Type{SquaredStruct{T}}, nt) where T = SquaredStruct{T}(nt.x^2)\n\ntypemap = function(f::JLD2.JLDFile, typepath::String, params::Vector)\n    if typepath == \"Main.OldStruct\"\n        if params[1] == Int\n            @info \"Mapping an OldStruct{Int} to SquaredStruct{Int} with conversion\"\n            # If the type param is Int, map to squared struct\n            # and wrap in `Upgrade` to trigger custom conversion with `rconvert`\n            return JLD2.Upgrade(SquaredStruct{Int})\n        else\n            @info \"Mapping an OldStruct{T} to NormalStruct{T} without conversion\"\n            # All other OldStructs just get updated to NormalStruct\n            return NormalStruct{params...}\n        end\n    end\n    # This typemap functino is called for every single type that is decoded.\n    # All types that do not need special handling should be forwarded to the default\n    # implementation.\n    @info \"Forwarding $typepath with parameters $params to default type mapping\"\n    return JLD2.default_typemap(f, typepath, params)\nend\n\nload(\"test.jld2\"; typemap)","category":"page"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"[ Info: Forwarding Core.Int64 with parameters Any[] to default type mapping\n[ Info: Mapping an OldStruct{Int} to SquaredStruct{Int} with conversion\n[ Info: Forwarding Core.Float64 with parameters Any[] to default type mapping\n[ Info: Mapping an OldStruct{T} to NormalStruct{T} without conversion\n[ Info: Forwarding Core.Int64 with parameters Any[] to default type mapping\n[ Info: Mapping an OldStruct{Int} to SquaredStruct{Int} with conversion\n[ Info: Forwarding Core.Float64 with parameters Any[] to default type mapping\n[ Info: Mapping an OldStruct{T} to NormalStruct{T} without conversion\nDict{String, Any} with 4 entries:\n  \"inttype\"   => SquaredStruct{Int64}\n  \"old_float\" => NormalStruct{Float64}(3.14)\n  \"old_int\"   => SquaredStruct{Int64}(1764)\n  \"floattype\" => NormalStruct{Float64}","category":"page"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"Note that the dictionary approach and the mapping function are mutually exclusive.","category":"page"},{"location":"advanced/#Groups-Appending-to-files","page":"Advanced Usage","title":"Groups - Appending to files","text":"","category":"section"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"Group objects can be constructed with two optional keyword arguments:","category":"page"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"g = Group(file;\n          est_num_entries=4\n          est_link_name_len=8)","category":"page"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"These determine how much (additional) empty space should be allocated for the group description. (list of entries) This can be useful for performance when one expects to append many additional datasets after first writing the file.","category":"page"},{"location":"advanced/#Fallback-Behaviour","page":"Advanced Usage","title":"Fallback Behaviour","text":"","category":"section"},{"location":"advanced/","page":"Advanced Usage","title":"Advanced Usage","text":"By default JLD2 will attempt to open files using the MmapIO backend. If that fails, it retries using IOStream.","category":"page"},{"location":"basic_usage/#Basic-usages:-reading-and-writing-data","page":"Basic Usage","title":"Basic usages: reading and writing data","text":"","category":"section"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"JLD2 provides a few different options to save and load data:","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"FileIO interface\nSingle object storage\nFile handles\nUnPack Extension","category":"page"},{"location":"basic_usage/#FileIO-interface","page":"Basic Usage","title":"FileIO interface","text":"","category":"section"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"The save and load functions, provided by FileIO, are one of the simplest ways to use JLD2. The save function accepts an AbstractDict yielding the key/value pairs, where the key is a string representing the name of the dataset and the value represents its contents:","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using JLD2\nsave(\"example.jld2\", Dict(\"hello\" => \"world\", \"foo\" => :bar))","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"The save function can also accept the dataset names and contents as arguments:","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using JLD2\nsave(\"example.jld2\", \"hello\", \"world\", \"foo\", :bar)","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"For save and load to automatically detect that you want to save a JLD2 file use the file suffix \".jld2\".","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"If called with a filename argument only, the load function loads all datasets from the given file into a Dict:","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using JLD2\nload(\"example.jld2\")","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"When called with a single dataset name, load returns the contents of that dataset from the file:","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using JLD2\nload(\"example.jld2\", \"hello\")","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"When called with multiple dataset names, load returns the contents of the given datasets as a tuple:","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using JLD2\nload(\"example.jld2\", \"foo\", \"hello\")","category":"page"},{"location":"basic_usage/#jldsave","page":"Basic Usage","title":"jldsave","text":"","category":"section"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"jldsave makes use of julia's keyword argument syntax to store files. This can be useful, when your data variables already have the correct name, e.g. use jldsave(file; variablename) instead of `save(file, \"variablename\", variablename)","category":"page"},{"location":"basic_usage/#JLD2.jldsave","page":"Basic Usage","title":"JLD2.jldsave","text":"jldsave(filename; kwargs...)\njldsave(filename, compress; kwargs...)\njldsave(filename, compress, iotype; kwargs...)\n\nCreates a JLD2 file at filename and stores the variables given as keyword arguments.\n\nExamples\n\njldsave(\"example.jld2\"; a=1, b=2, c)\n\nis equivalent to\n\njldopen(\"example.jld2\", \"w\") do f\n    f[\"a\"] = 1\n    f[\"b\"] = 2\n    f[\"c\"] = c\nend\n\nTo choose the io type IOStream instead of the default MmapIO use  jldsave(fn, IOStream; kwargs...).\n\n\n\n\n\n","category":"function"},{"location":"basic_usage/#Single-object-storage","page":"Basic Usage","title":"Single object storage","text":"","category":"section"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"If only a single object needs to stored and loaded from a file, one can use save_object and load_object functions.","category":"page"},{"location":"basic_usage/#JLD2.save_object","page":"Basic Usage","title":"JLD2.save_object","text":"save_object(filename, x)\n\nStores an object x in a new JLD2 file at filename. If a file exists at this path, it will be overwritten.\n\nSince the JLD2 format requires that all objects have a name, the object will be stored as single_stored_object. If you want to store more than one object, use @save macro, jldopen or the FileIO API.\n\nExample\n\nTo save the string hello to the JLD2 file example.jld2:\n\nhello = \"world\"\nsave_object(\"example.jld2\", hello)\n\n\n\n\n\n","category":"function"},{"location":"basic_usage/#JLD2.load_object","page":"Basic Usage","title":"JLD2.load_object","text":"load_object(filename)\n\nReturns the only available object from the JLD2 file filename (The stored object name is inconsequential). If the file contains more than one or no objects, the function throws an ArgumentError.\n\nFor loading more than one object, use @load macro, jldopen or the FileIO API.\n\nExample\n\nTo load the only object from the JLD2 file example.jld2:\n\nhello = \"world\"\nsave_object(\"example.jld2\", hello)\nhello_loaded = load_object(\"example.jld2\")\n\n\n\n\n\n","category":"function"},{"location":"basic_usage/#File-handles","page":"Basic Usage","title":"File handles","text":"","category":"section"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"It is also possible to interact with JLD2 files using a file-like interface. The jldopen function accepts a file name and an argument specifying how the file should be opened:","category":"page"},{"location":"basic_usage/#JLD2.jldopen","page":"Basic Usage","title":"JLD2.jldopen","text":"jldopen(file, mode::AbstractString; iotype=MmapIO, compress=false, typemap=JLD2.default_typemap)\n\nOpens a JLD2 file at path file. Alternatively file may be a suitable IO object.\n\nOptions for mode:\n\n\"r\": Open for reading only, failing if no file exists\n\"r+\": Open for reading and writing, failing if no file exists\n\"w\"/\"w+\": Open for reading and writing, overwriting the file if it already exists\n\"a\"/\"a+\": Open for reading and writing, creating a new file if none exists, but               preserving the existing file if one is present\n\n\n\n\n\n","category":"function"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"Data can be written to the file using write(f, \"name\", data) or f[\"name\"] = data, or read from the file using read(f, \"name\") or f[\"name\"]. When you are done with the file, remember to call close(f).","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"Like open, jldopen also accepts a function as the first argument, permitting do-block syntax:","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using JLD2\njldopen(\"example.jld2\", \"w\") do f\n    write(f, \"variant1\", 1.0)\n    f[\"variant2\"] = (rand(5), rand(Bool, 3))\nend\n\nf = jldopen(\"example.jld2\")\nv1 = read(f, \"variant1\")\nv2 = f[\"variant2\"]\nclose(f)\nv1, v2","category":"page"},{"location":"basic_usage/#Groups","page":"Basic Usage","title":"Groups","text":"","category":"section"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"JLD2 files allow for nesting datasets into groups which may be useful for organizing your data. You may construct groups explicitly:","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using JLD2\njldopen(\"example.jld2\", \"w\") do file\n    mygroup = JLD2.Group(file, \"mygroup\")\n    mygroup[\"mystuff\"] = 42\n    display(file)\nend","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"or implicitly, by saving a variable with a name containing slashes as path delimiters:","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using JLD2\nsave(\"example.jld2\", \"mygroup/mystuff\", 42)","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"Similarly, you can access groups directly:","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using JLD2\njldopen(\"example.jld2\") do file\n    file[\"mygroup\"][\"mystuff\"]\nend","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"or using slashes as path delimiters:","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using JLD2\nload(\"example.jld2\", \"mygroup/mystuff\")","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"When loading files with nested groups these will be unrolled into paths by default but yield nested dictionaries but with the nested keyword argument.","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"load(\"example.jld2\")\nload(\"example.jld2\"; nested=true)","category":"page"},{"location":"basic_usage/#UnPack-Extension","page":"Basic Usage","title":"UnPack Extension","text":"","category":"section"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"When additionally loading the UnPack.jl package, its @unpack and @pack! macros can be used to quickly save and load data from the file-like interface. Example:","category":"page"},{"location":"basic_usage/","page":"Basic Usage","title":"Basic Usage","text":"using JLD2, UnPack\nfile = jldopen(\"example.jld2\", \"w\")\nx, y = rand(2)\n\n@pack! file = x, y # equivalent to file[\"x\"] = x; file[\"y\"] = y\n@unpack x, y = file # equivalent to x = file[\"x\"]; y = file[\"y\"]\nclose(file)","category":"page"},{"location":"customserialization/#Custom-Serialization","page":"Custom Serialization","title":"Custom Serialization","text":"","category":"section"},{"location":"customserialization/","page":"Custom Serialization","title":"Custom Serialization","text":"JLD2 makes it easy to define custom serialization for your own types. To do this, define a new type (e.g. ASerialization) that contains the fields you want to store, and then tell JLD2 how to convert between your type and the serialization type.","category":"page"},{"location":"customserialization/","page":"Custom Serialization","title":"Custom Serialization","text":"For example:","category":"page"},{"location":"customserialization/","page":"Custom Serialization","title":"Custom Serialization","text":"struct A\n    x::Int\nend\n\nstruct ASerialization\n    x::Vector{Int}\nend\n\nJLD2.writeas(::Type{A}) = ASerialization\nBase.convert(::Type{ASerialization}, a::A) = ASerialization([a.x])\nBase.convert(::Type{A}, a::ASerialization) = A(only(a.x))","category":"page"},{"location":"customserialization/","page":"Custom Serialization","title":"Custom Serialization","text":"JLD2 will automatically use these conversions when saving and loading objects of type A.","category":"page"},{"location":"customserialization/","page":"Custom Serialization","title":"Custom Serialization","text":"warning: Already defined custom serialization\nSome Julia built-in types already use custom serialization, and JLD2 cannot nest these. To avoid unexpected behavior, always define a wrapper type for your serialization (as in the example above, where ASerialization is used instead of a plain Vector{Int}). In particular, avoid using built-in types like <: AbstractDict or <: Array directly as your serialization type.","category":"page"},{"location":"customserialization/","page":"Custom Serialization","title":"Custom Serialization","text":"If you prefer not to overload Base.convert, you can instead define the following methods:","category":"page"},{"location":"customserialization/","page":"Custom Serialization","title":"Custom Serialization","text":"JLD2.wconvert(::Type{ASerialization}, a::A) = ASerialization([a.x])\nJLD2.rconvert(::Type{A}, a::ASerialization) = A(only(a.x))","category":"page"},{"location":"customserialization/","page":"Custom Serialization","title":"Custom Serialization","text":"This approach is especially useful if you do not own the type you want to serialize, or want to avoid extending Base.","category":"page"},{"location":"customserialization/","page":"Custom Serialization","title":"Custom Serialization","text":"Here's another example:","category":"page"},{"location":"customserialization/","page":"Custom Serialization","title":"Custom Serialization","text":"struct B\n    x::Float64\nend\n\nJLD2.writeas(::Type{B}) = Float64\nJLD2.wconvert(::Type{Float64}, b::B) = b.x\nJLD2.rconvert(::Type{B}, x::Float64) = B(x)\n\narr = [B(rand()) for i in 1:10]\n\n@save \"test.jld2\" arr","category":"page"},{"location":"customserialization/","page":"Custom Serialization","title":"Custom Serialization","text":"In this example, JLD2 converts the array of B structs to a plain Vector{Float64} before storing it to disk.","category":"page"},{"location":"hdf5compat/#HDF5-Compatibility","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"","category":"section"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"JLD2 is built upon the HDF5 Format Specification and produces files that are compatible with the official HDF5 C library.","category":"page"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"This has the advantage that other libraries that use HDF5 such as the Julia wrapper HDF5.jl or  even with h5py using Python. In addition to that, adhering to the HDF5 standards allows you to use the file introspection tools  such as h5dump and h5debug provided by the HDF5 group.","category":"page"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"warning: Warning\nGeneral compatibility only holds for a list of basic types:Numbers FloatXX, IntXX and UIntXX\nBools\nStrings\nArrays of those typesOther structures can in principle also be decoded but may involve work. See below for more information","category":"page"},{"location":"hdf5compat/#Understanding-how-Julia-structs-are-encoded","page":"HDF5 Compatibility","title":"Understanding how Julia structs are encoded","text":"","category":"section"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"The HDF5 standard supports so-called compound datatypes that comprise of a set of  already known datatypes. This is very similar to julia's structs.  When a user wants to write a non-default type to disk then JLD2 will create the corresponding compound datatypes and commit them to the file. All custom type definitions in a JLD2 file will be stored  in a _types/ group. This way, the type definitions only needs to be written to the file once and all instances of that struct reference it.","category":"page"},{"location":"hdf5compat/#Example","page":"HDF5 Compatibility","title":"Example","text":"","category":"section"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"using JLD2\n\nstruct MyCustomStruct\n    x::Int64\n    y::Float64\nend\n\n@save \"test.jld2\" a=MyCustomStruct(42, π)","category":"page"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"Let's see what JLD2 makes out of my simple MyCustomStruct. To do that we view the output of h5dump","category":"page"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"$ h5dump test.jld2\nHDF5 \"test.jld2\" {\nGROUP \"/\" {\n   GROUP \"_types\" {\n      DATATYPE \"00000001\" H5T_COMPOUND {\n         H5T_STRING {\n            STRSIZE H5T_VARIABLE;\n            STRPAD H5T_STR_NULLPAD;\n            CSET H5T_CSET_UTF8;\n            CTYPE H5T_C_S1;\n         } \"name\";\n         H5T_VLEN { H5T_REFERENCE { H5T_STD_REF_OBJECT }} \"parameters\";\n      }\n         ATTRIBUTE \"julia_type\" {\n            DATATYPE  \"/_types/00000001\"\n            DATASPACE  SCALAR\n            DATA {\n            (0): {\n                  \"Core.DataType\",\n                  ()\n               }\n            }\n         }\n      DATATYPE \"00000002\" H5T_COMPOUND {\n         H5T_STD_I64LE \"x\";\n         H5T_IEEE_F64LE \"y\";\n      }\n         ATTRIBUTE \"julia_type\" {\n            DATATYPE  \"/_types/00000001\"\n            DATASPACE  SCALAR\n            DATA {\n            (0): {\n                  \"Main.MyCustomStruct\",\n                  ()\n               }\n            }\n         }\n   }\n   DATASET \"a\" {\n      DATATYPE  \"/_types/00000002\"\n      DATASPACE  SCALAR\n      DATA {\n      (0): {\n            42,\n            3.14159\n         }\n      }\n   }\n}\n}","category":"page"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"We can see that the file contains two things at top-level. There is a dataset \"a\" (that is what we wanted to store) and there is a group _types which is where all the necessary type information is stored.","category":"page"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"You can see that JLD2 committed two compound datatypes. The first one is Core.Datatype which at first seems rather unintuitive. It is needed to tell HDF5 what a serialized  julia datatype looks like (a name and a list of parameters).","category":"page"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"Below that is the definition of MyCustomStruct with two fields  H5T_STD_I64LE \"x\" and H5T_IEEE_F64LE \"y\" defining the integer field x and the float field y.","category":"page"},{"location":"hdf5compat/#A-note-on-pointers","page":"HDF5 Compatibility","title":"A note on pointers","text":"","category":"section"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"In the julia programming language pointers Ptr are not needed very often. However, when binary dependencies come into play and memory is passed back and forth, pointers do become relevant. Pointers are addresses to locations in memory and thus lose their meaning after a program has terminated.","category":"page"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"In principle, there is little point in storing a pointer to a file but in order to allow for a more seamless experience JLD2 will, similar to Base.Serialization silently accept pointers. This is useful when storing large structures such as a DifferentialEquations.jl solution object that might contain a pointer somewhere. Upon deserialization any pointer fields are instantiated as null pointers.","category":"page"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"This is done with just three lines of code utilizing the custom serialization logic and  it is shown here as it serves as a good example for usage of that feature.","category":"page"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"writeas(::Type{<:Ptr}) = Nothing\nrconvert(::Type{Ptr{T}}, ::Nothing) where {T} = Ptr{T}()","category":"page"},{"location":"hdf5compat/","page":"HDF5 Compatibility","title":"HDF5 Compatibility","text":"Usually one would also have to define a method for wconvert. However, in this  case JLD2 figures out that no explicit conversion is needed to construct nothing.","category":"page"},{"location":"compression/#Compression","page":"Compression","title":"Compression","text":"","category":"section"},{"location":"compression/","page":"Compression","title":"Compression","text":"JLD2 supports compression of isbits arrays. This includes the typical Array{Float64} but also arrays of custom structs that are immutable and only consist of basic number type fields.","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"To enable the default compression, you can write:","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"using JLD2\nsave(\"example.jld2\", \"large_array\", zeros(10000); compress = true)","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"Alternatively use","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"jldsave(\"example.jld2\", true; large_array=zeros(10000))","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"or","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"jldopen(\"example.jld2\", \"w\"; compress = true) do f\n    f[\"large_array\"] = zeros(10000)\nend","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"When reading a file JLD2 detects compression and automatically decompresses the data so it is not necessary to pass any extra parameters for that case. However, JLD2 will prompt you to install and load the necessary filter packages if they are not yet available.","category":"page"},{"location":"compression/#Compression-Filter-API","page":"Compression","title":"Compression Filter API","text":"","category":"section"},{"location":"compression/","page":"Compression","title":"Compression","text":"JLD2 can use a number of different compression algorithms, also called filters. These can be used individually and even chained which can be useful for some types of data. The filter used by compress = true is the Deflate() compression filter.","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"note: Note\nThe default Deflate() compression is always available but some others will need to be installed separately. JLD2 will throw an error if the required filter package is not loaded, prompting you to install and load the appropriate package e.g. : using JLD2, JLD2Lz4.","category":"page"},{"location":"compression/#Installing-Filter-Packages","page":"Compression","title":"Installing Filter Packages","text":"","category":"section"},{"location":"compression/","page":"Compression","title":"Compression","text":"To use compression filters, you need to install and load the corresponding packages:","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"using Pkg\n# For other compression algorithms\nPkg.add(\"JLD2Lz4\")\nusing JLD2, JLD2Lz4  # Load the package you need","category":"page"},{"location":"compression/#Available-Compression-Filters","page":"Compression","title":"Available Compression Filters","text":"","category":"section"},{"location":"compression/","page":"Compression","title":"Compression","text":"This compression system is analogous to that of HDF5 and uses the same underlying compression libraries. JLD2 files with compressed datasets can in many cases be opened using HDF5 and similarly, JLD2 will be able to read most HDF5 files even with compression. The compression filters available for JLD2 are:","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"Filter Package Filter Type Notes\nbuilt in Shuffle Rearrangement of bytes useful as a preprocess filter\nbuilt in Deflate Default compression, very widely used, good compatibility\nbuilt in ZstdFilter Fast, wide range of compression size vs speed trade-offs\nJLD2Bzip2 Bzip2Filter Good compression ratio, can be slower\nJLD2Lz4 Lz4Filter Very fast compression/decompression","category":"page"},{"location":"compression/#Using-Specific-Filters","page":"Compression","title":"Using Specific Filters","text":"","category":"section"},{"location":"compression/","page":"Compression","title":"Compression","text":"To use a specific compression filter, pass an instance of the filter instead of true:","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"using JLD2, JLD2Lz4\n\n# Using Lz4 compression\njldopen(\"example.jld2\", \"w\"; compress = Lz4Filter()) do f\n    f[\"large_array\"] = zeros(10000)\nend\n\n# Zstd with non-standard compression level\njldopen(\"example.jld2\", \"w\"; compress = ZstdFilter(9)) do f\n    f[\"large_array\"] = zeros(10000)\nend","category":"page"},{"location":"compression/#Using-Multiple-Filters","page":"Compression","title":"Using Multiple Filters","text":"","category":"section"},{"location":"compression/","page":"Compression","title":"Compression","text":"JLD2 supports combining multiple filters for advanced compression strategies. This is particularly useful when combining preprocessing filters (like shuffling) with compression filters. Simply provide a vector of filters:","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"using JLD2\n\n# Combine Shuffle preprocessing with Deflate compression\nfilters = [Shuffle(), Deflate()]\n\njldopen(\"example.jld2\", \"w\"; compress = filters) do f\n    # Benefits from byte shuffling\n    # Only the lowest byte of each element is non-zero\n    # Shuffle() reorders the bytes of all elements from e.g.\n    # [123123123] to [111222333]\n    # where each digit refers to the nth byte of an array element.\n    f[\"numeric_data\"] = UInt.(rand(UInt8, 10000))\nend","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"note: Note\nFilters in a pipeline are applied in order during compression and in reverse order during decompression. Preprocessing filters (like Shuffle) should typically come before compression filters.","category":"page"},{"location":"compression/#Filter-Configuration-Examples","page":"Compression","title":"Filter Configuration Examples","text":"","category":"section"},{"location":"compression/","page":"Compression","title":"Compression","text":"Different filters support various configuration options:","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"using JLD2, JLD2Lz4, JLD2Bzip2\n\n# Zstd with different compression levels\nzstd_fast = ZstdFilter(1)    # Fast compression\nzstd_best = ZstdFilter(22)   # Best compression\n\n# Bzip2 with custom block size\nbzip2_filter = Bzip2Filter(4)\n\n# Example usage\njldopen(\"example.jld2\", \"w\") do f\n    write(f, \"fast_data\", zeros(UInt8, 10000); compress=zstd_fast)\n    write(f, \"small_data\", randn(10000); compress=zstd_best)\n    write(f, \"archive_data\", randn(1000); compress=bzip2_filter)\nend","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"Depending on the characteristics of your datasets, some configurations may be more efficient than others.","category":"page"},{"location":"compression/#Manually-selecting-compression-for-datasets","page":"Compression","title":"Manually selecting compression for datasets","text":"","category":"section"},{"location":"compression/","page":"Compression","title":"Compression","text":"Sometimes you may know that some of your arrays are easily compressible and that for others it is not worth the effort. For precise control, the write function takes an optional keyword argument to override the file compression settings.","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"using JLD2\n\njldopen(\"example.jld2\", \"w\"; compress=ZstdFilter()) do f\n    # This gets compressed with the ZstdFilter\n    write(f, \"default_array\", zeros(10000))\n\n    # Don't compress this\n    write(f, \"random_array\", rand(10000); compress=false)\n\n    # Override the above compression filter and use a different one\n    write(f, \"zlib_array\", zeros(10000); compress=Deflate())\n\n    # Alternatively, use the same filter but with different configuration\n    write(f, \"fast_compressed\", rand(10000); compress=ZstdFilter(1))\nend","category":"page"},{"location":"compression/#Compatibility-and-Migration-from-v0.5-to-v0.6","page":"Compression","title":"Compatibility and Migration from v0.5 to v0.6","text":"","category":"section"},{"location":"compression/","page":"Compression","title":"Compression","text":"File Compatibility: Files created with the old API can be read with the new system. Files created with the v0.6 filter API may not be able to read by older versions of JLD2, see the compatibility table below for more information.\nPerformance: Compression performance and file sizes remain the same as the underlying compression libraries are unchanged.\nHDF5 Compatibility: The new API is analogous to HDF5.jl, making it easier to work with HDF5 files and improving interoperability.","category":"page"},{"location":"compression/#Filter-Compatibility-Table","page":"Compression","title":"Filter Compatibility Table","text":"","category":"section"},{"location":"compression/","page":"Compression","title":"Compression","text":"The following table shows which JLD2 versions can decode data compressed using different filter features:","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"Filter feature JLD2 versions able to decode\nDeflate Since 0.2.0\nBzip2Filter Since 0.4.4\nZstdFilter Since 0.4.49\nShuffle Since 0.6.0\nLz4Filter Since 0.6.0\nmultiple filters Since 0.6.0","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"Notes:","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"Data compressed with LZ4FrameCompressor in previous versions","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"can be read if JLD2Lz4 is loaded. Data compressed with Lz4Filter cannot be read by JLD2 versions before 0.6.0.","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"For code migration, the main change is in how you specify compression filters:","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"# Old API\n# using JLD2, CodecZlib\n# jldopen(\"file.jld2\", \"w\"; compress = ZlibCompressor()) do f\n\n# New API\nusing JLD2\njldopen(\"file.jld2\", \"w\"; compress = Deflate()) do f\n    # ...\nend","category":"page"},{"location":"compression/","page":"Compression","title":"Compression","text":"The simplest usage option of compress=true still works as before.","category":"page"},{"location":"compression/#API-Docstrings","page":"Compression","title":"API Docstrings","text":"","category":"section"},{"location":"compression/#JLD2.Filters","page":"Compression","title":"JLD2.Filters","text":"JLD2.Filters\n\nThis module contains the interface for using filters in JLD2.jl.\n\n\n\n\n\n","category":"module"},{"location":"compression/#JLD2.Filters.Deflate","page":"Compression","title":"JLD2.Filters.Deflate","text":"Deflate <: Filter\n\nThe Deflate filter can be used to compress datasets. It uses the well-known and widely used zlib (deflate) compression algorithm.\n\nArguments:\n\nlevel: Compression level, between 0 and 9. Default is 5.\n\nLarger numbers lead to better compression, but also to longer runtime.\n\n\n\n\n\n","category":"type"},{"location":"compression/#JLD2.Filters.Shuffle","page":"Compression","title":"JLD2.Filters.Shuffle","text":"Shuffle <: Filter\n\nThe Shuffle filter can be used as part of a filter pipeline to compress datasets. It rearranges the bytes of elements in an array to improve compression efficiency. It is not a compression filter by itself, but can be used in conjunction with other compression filters like DeflateorZstdFilter`.\n\nIt can be useful when the array, for example, contains unsigned integer UInt64 and all values are small. Then all the upper bytes of the eight byte integer are zero. This filter will rearrange the bytes so that all the least significant bytes are at the beginning of the array, followed by the second least significant bytes, and so on, which simplifies the compression of the data.\n\n\n\n\n\n","category":"type"},{"location":"compression/#JLD2.Filters.ZstdFilter","page":"Compression","title":"JLD2.Filters.ZstdFilter","text":"ZstdFilter <: Filter\n\nThe ZstdFilter can be used to compress datasets using the Zstandard compression algorithm.\n\nArguments:\n\nlevel: Compression level, between 1 and 22.\n\nLarger numbers lead to better compression, but also to longer runtime.\n\n\n\n\n\n","category":"type"},{"location":"#Welcome-to-**JLD2.jl**","page":"Home","title":"Welcome to JLD2.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"JLD2.jl is a high-performance, pure Julia library for saving and loading arbitrary Julia data structures. It's designed as a fast binary serialization format that produces files according to the well-known HDF5 format but doesn't rely on external libraries like the HDF5 C-library — making it an ideal choice for native Julia workflows.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#What-is-JLD2.jl?","page":"Home","title":"📦 What is JLD2.jl?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"JLD2 stands for Julia Data Format 2, a file format and serialization library tailored to work seamlessly with native Julia types. Whether you're working with arrays, dictionaries, structs, or custom types, JLD2 provides a reliable way to store your data to disk and retrieve it later — all in pure Julia.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Why-Use-JLD2?","page":"Home","title":"🚀 Why Use JLD2?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"✅ Save and load any Julia type, including custom structs\n✅ Fast and efficient, thanks to native Julia code\n✅ Custom IO support — can read and write to either Vector{UInt8} or custom IO implementations\n✅ Portable within Julia versions — great for caching, prototyping, and long-term storage\n✅ Customizable type loading — offers fine-grained control to update outdated stored structures upon load","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Example:-Saving-and-Loading-Data","page":"Home","title":"✨ Example: Saving and Loading Data","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"using JLD2\n\n# Some sample data\nmodel = (name = \"Transformer\", layers = 12, params = 300_000_000)\nscores = [0.91, 0.87, 0.93]\n\n# Save to a file\n@save \"model_state.jld2\" model scores\n\n# Load back later\n@load \"model_state.jld2\" model scores\n\nprintln(model.name)  # Output: Transformer","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can also save individual variables or load just what you need:","category":"page"},{"location":"","page":"Home","title":"Home","text":"@save \"data.jld2\" a=1 b=[1,2,3] c=\"hi\"\n@load \"data.jld2\" b c","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Related-Serialization-libraries-in-Julia","page":"Home","title":"📊 Related Serialization libraries in Julia","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Below is a comparison of JLD2 and other common Julia libraries for data storage and serialization. Choose the tool that best fits your needs:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Library Best For Notes\nJLD2.jl Native Julia data (structs, arrays, Dicts, etc.) Fast, flexible, pure Julia, HDF5-compatible, no external dependencies\nSerialization.jl Any Julia object Built-in, very fast, but not cross-version safe or portable outside Julia\nMAT.jl Interop with MATLAB .mat files Read/write MATLAB files, good for sharing with MATLAB users\nHDF5.jl Full-featured HDF5 access Direct interface to HDF5 C library, cross-language, supports advanced HDF5 features\nArrow.jl Tabular data, dataframes, analytics Excellent for columnar data, cross-language (Python, R, etc.), DataFrame support\nCSV.jl Lightweight table exports/imports Great for human-readable, row-based data, simple and widely supported\nJSON.jl Web services, config files, nested dicts Portable, text-based, less efficient for complex Julia types","category":"page"},{"location":"","page":"Home","title":"Home","text":"If your goal is to store structured tables (like DataFrames) for analysis or sharing between tools, Arrow.jl or CSV.jl may be a better fit. But if you're dealing with rich, nested, Julia-native data, or just want a fast way to persist your models, simulations, or internal state, JLD2 is the right tool.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Contributing","page":"Home","title":"💬 Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"JLD2 is community-driven! We welcome contributions, bug reports, and suggestions at the GitHub repository.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you're interested in improving documentation, fixing issues, or proposing new features, we’d love your help.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Next-Steps","page":"Home","title":"🧭 Next Steps","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Use the sidebar to navigate:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Usage Guide\nCustom serialization\nCompression\nAdvanced Tips\nHDF5 compatibility\nGotchas & Troubleshooting","category":"page"}]
}
